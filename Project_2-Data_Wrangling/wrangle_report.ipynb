{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporting: wragle_report\n",
    "* Create a **300-600 word written report** called \"wrangle_report.pdf\" or \"wrangle_report.html\" that briefly describes your wrangling efforts. This is to be framed as an internal document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Input\n",
    "The first dataset that was meant to be downloaded manually was relatively easy to import. This was done by clicking on the hyperlink provided to me, moving the data into the relevant directory and importing using Python's Pandas package using the pandas.read_csv() function.\n",
    "\n",
    "The next dataset was meant to be downloaded programatically using the Requests package. The package takes a URL and saves the response to a variable which can then be saved or written to a relevant file before being imported again with Pandas.\n",
    "\n",
    "The final dataset was not trivial to download. I used some code from another repository to help me a little with this section and referenced it in the README file.\n",
    "\n",
    "The connection to the twitter API was done using tweepy the response was written to data/tweet_json.txt using the json library and the open command as can be seen at in the ipynb/html file. The problem I encountered here was that downloading the tweet_json.txt file required APIv2 access, so i used the tweet-json.txt file provided by udacity. \n",
    "\n",
    "The text file that was created was not very easy to handle because of how big it is (about 10MB). For some reason I have a hard time opening it in any kind of notepad file. However, importing it and selecting the information I required using pandas was relatively straightforward as above.\n",
    "\n",
    "### Data Assessment\n",
    "Next, the imported data needed to be assessed for quality issues. This was done programmatically within my ipynb file and visually. Visual assessment was done after most noticable assessment had been conducted programmatically.\n",
    "\n",
    "#### Visual Assessment\n",
    "I could recreate what I wrote in my jupyter notebook file, but this would be a waste of time so I'll just keep this brief.\n",
    "\n",
    "Basic problems many missing data (None, NaN). It was also noted that many of the images that were sent to @WeRateDogs were not actually dogs at all! Removing these images would be important for assessment.\n",
    "\n",
    "#### Programmatic Assessment\n",
    "The programatic assessment is where I found most of the issues that I wanted to address during the wrangling phase. It is worth noting however that there is not a hard line between what constitutes programmatic and visual, as i noted within the notebook itself. The general problems that I found was missing values using pandas.DataFrame.info(), which I used quite a lot throughout the wrangling process. The tweet_id was always an integer when it should have been a string (see Ordinal vs Categorical values), many retweets or replies and duplicates which where not original tweets needed for analyses and insights.\n",
    "\n",
    "Overall, it was a very tidious process going over tweeted texts to identify and recover names and ratings that were missed or wrongly coded.\n",
    "\n",
    "### Data Cleaning\n",
    "During the cleaning I solved the problems that I outlined in the Assessment stage.\n",
    "The defined Step-by-step guide came in really handy in addressing the documented observed quality and tidiness issues noticed in the assessment stage. This stage took a lot less time than the visual assessment stage.\n",
    "\n",
    "### Data Output\n",
    "After the data cleaning was completed, I created a CSV file.\n",
    "\n",
    "The CSV creation was much less interesting, that was just done using pandas.DataFrame.to_csv()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
